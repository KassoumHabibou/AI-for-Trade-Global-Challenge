{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e748536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2021 import...\n",
      "  Found 12 files\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202101_HS4.csv: 34602 rows -> 34602 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202102_HS4.csv: 34643 rows -> 34643 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202103_HS4.csv: 36205 rows -> 36205 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202104_HS4.csv: 36312 rows -> 36312 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202105_HS4.csv: 36331 rows -> 36331 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202106_HS4.csv: 36621 rows -> 36621 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202107_HS4.csv: 36592 rows -> 36592 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202108_HS4.csv: 36553 rows -> 36553 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202109_HS4.csv: 36298 rows -> 36298 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202110_HS4.csv: 36475 rows -> 36475 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202111_HS4.csv: 36976 rows -> 36976 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202112_HS4.csv: 36849 rows -> 36849 rows after filtering (qty >= 0)\n",
      "\n",
      "  Merged dataframe info:\n",
      "    Total rows: 434,457\n",
      "    First 5 columns: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "    Sample data:\n",
      "  typeCode freqCode  refPeriodId     qty\n",
      "0        C        M     20210101  3902.0\n",
      "1        C        M     20210101    67.0\n",
      "2        C        M     20210101    11.0\n",
      "3        C        M     20210101    89.0\n",
      "4        C        M     20210101    20.0\n",
      "\n",
      "  ✓✓ SAVED: comtrade_monthly_hs4_outputs/merged\\USA_2021_import.csv\n",
      "\n",
      "Processing 2021 export...\n",
      "  Found 12 files\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202101_HS4.csv: 55319 rows -> 55319 rows after filtering (qty >= 0)\n",
      "    Adding 2 placeholder column names\n",
      "    ✓ USA_X_202102_HS4.csv: 55246 rows -> 55246 rows after filtering (qty >= 0)\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202103_HS4.csv: 58373 rows -> 58373 rows after filtering (qty >= 0)\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202104_HS4.csv: 57505 rows -> 57505 rows after filtering (qty >= 0)\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202105_HS4.csv: 57840 rows -> 57840 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202106_HS4.csv: 57239 rows -> 57239 rows after filtering (qty >= 0)\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202107_HS4.csv: 57078 rows -> 57078 rows after filtering (qty >= 0)\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202108_HS4.csv: 56691 rows -> 56691 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202109_HS4.csv: 56551 rows -> 56551 rows after filtering (qty >= 0)\n",
      "    Adding 2 placeholder column names\n",
      "    ✓ USA_X_202110_HS4.csv: 58297 rows -> 58297 rows after filtering (qty >= 0)\n",
      "    Adding 2 placeholder column names\n",
      "    ✓ USA_X_202111_HS4.csv: 57082 rows -> 57082 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202112_HS4.csv: 57317 rows -> 57317 rows after filtering (qty >= 0)\n",
      "\n",
      "  Merged dataframe info:\n",
      "    Total rows: 684,538\n",
      "    First 5 columns: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "    Sample data:\n",
      "  typeCode freqCode  refPeriodId  qty\n",
      "0        C        M     20210101  0.0\n",
      "1        C        M     20210101  0.0\n",
      "2        C        M     20210101  0.0\n",
      "3        C        M     20210101  0.0\n",
      "4        C        M     20210101  0.0\n",
      "\n",
      "  ✓✓ SAVED: comtrade_monthly_hs4_outputs/merged\\USA_2021_export.csv\n",
      "\n",
      "Processing 2022 import...\n",
      "  Found 12 files\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202201_HS4.csv: 35657 rows -> 35657 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202202_HS4.csv: 35735 rows -> 35735 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202203_HS4.csv: 37178 rows -> 37178 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202204_HS4.csv: 36469 rows -> 36469 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202205_HS4.csv: 36908 rows -> 36908 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202206_HS4.csv: 37177 rows -> 37177 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202207_HS4.csv: 36384 rows -> 36384 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202208_HS4.csv: 36745 rows -> 36745 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202209_HS4.csv: 36569 rows -> 36569 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202210_HS4.csv: 58658 rows -> 58658 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202211_HS4.csv: 36624 rows -> 36624 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202212_HS4.csv: 36363 rows -> 36363 rows after filtering (qty >= 0)\n",
      "\n",
      "  Merged dataframe info:\n",
      "    Total rows: 460,467\n",
      "    First 5 columns: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "    Sample data:\n",
      "  typeCode freqCode  refPeriodId      qty\n",
      "0        C        M     20220101    0.000\n",
      "1        C        M     20220101   83.417\n",
      "2        C        M     20220101    0.000\n",
      "3        C        M     20220101  467.197\n",
      "4        C        M     20220101   77.506\n",
      "\n",
      "  ✓✓ SAVED: comtrade_monthly_hs4_outputs/merged\\USA_2022_import.csv\n",
      "\n",
      "Processing 2022 export...\n",
      "  Found 12 files\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202201_HS4.csv: 55145 rows -> 55145 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202202_HS4.csv: 56621 rows -> 56621 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202203_HS4.csv: 58739 rows -> 58739 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202204_HS4.csv: 58181 rows -> 58181 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202205_HS4.csv: 57839 rows -> 57839 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202206_HS4.csv: 58133 rows -> 58133 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202207_HS4.csv: 57380 rows -> 57380 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202208_HS4.csv: 58091 rows -> 58091 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202209_HS4.csv: 57911 rows -> 57911 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202210_HS4.csv: 58658 rows -> 58658 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202211_HS4.csv: 57451 rows -> 57451 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202212_HS4.csv: 57288 rows -> 57288 rows after filtering (qty >= 0)\n",
      "\n",
      "  Merged dataframe info:\n",
      "    Total rows: 691,437\n",
      "    First 5 columns: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "    Sample data:\n",
      "  typeCode freqCode  refPeriodId     qty\n",
      "0        C        M     20220101  6547.0\n",
      "1        C        M     20220101     5.0\n",
      "2        C        M     20220101     1.0\n",
      "3        C        M     20220101    12.0\n",
      "4        C        M     20220101    10.0\n",
      "\n",
      "  ✓✓ SAVED: comtrade_monthly_hs4_outputs/merged\\USA_2022_export.csv\n",
      "\n",
      "Processing 2025 import...\n",
      "  Found 7 files\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202501_HS4.csv: 36022 rows -> 36022 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202502_HS4.csv: 36022 rows -> 36022 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202503_HS4.csv: 36996 rows -> 36996 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202504_HS4.csv: 37095 rows -> 37095 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202505_HS4.csv: 36850 rows -> 36850 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202506_HS4.csv: 36730 rows -> 36730 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_M_202507_HS4.csv: 37174 rows -> 37174 rows after filtering (qty >= 0)\n",
      "\n",
      "  Merged dataframe info:\n",
      "    Total rows: 256,889\n",
      "    First 5 columns: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "    Sample data:\n",
      "  typeCode freqCode  refPeriodId     qty\n",
      "0        C        M     20250101  1819.0\n",
      "1        C        M     20250101   188.0\n",
      "2        C        M     20250101     1.0\n",
      "3        C        M     20250101   193.0\n",
      "4        C        M     20250101    17.0\n",
      "\n",
      "  ✓✓ SAVED: comtrade_monthly_hs4_outputs/merged\\USA_2025_import.csv\n",
      "\n",
      "Processing 2025 export...\n",
      "  Found 7 files\n",
      "    Adding 2 placeholder column names\n",
      "    ✓ USA_X_202501_HS4.csv: 54865 rows -> 54865 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202502_HS4.csv: 56409 rows -> 56409 rows after filtering (qty >= 0)\n",
      "    Adding 5 placeholder column names\n",
      "    ✓ USA_X_202503_HS4.csv: 58248 rows -> 58248 rows after filtering (qty >= 0)\n",
      "    Adding 1 placeholder column names\n",
      "    ✓ USA_X_202504_HS4.csv: 57374 rows -> 57374 rows after filtering (qty >= 0)\n",
      "    Adding 3 placeholder column names\n",
      "    ✓ USA_X_202505_HS4.csv: 57530 rows -> 57530 rows after filtering (qty >= 0)\n",
      "    Adding 5 placeholder column names\n",
      "    ✓ USA_X_202506_HS4.csv: 56240 rows -> 56240 rows after filtering (qty >= 0)\n",
      "    Adding 2 placeholder column names\n",
      "    ✓ USA_X_202507_HS4.csv: 56718 rows -> 56718 rows after filtering (qty >= 0)\n",
      "\n",
      "  Merged dataframe info:\n",
      "    Total rows: 397,384\n",
      "    First 5 columns: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "    Sample data:\n",
      "  typeCode freqCode  refPeriodId  qty\n",
      "0        C        M     20250101  0.0\n",
      "1        C        M     20250101  0.0\n",
      "2        C        M     20250101  0.0\n",
      "3        C        M     20250101  0.0\n",
      "4        C        M     20250101  0.0\n",
      "\n",
      "  ✓✓ SAVED: comtrade_monthly_hs4_outputs/merged\\USA_2025_export.csv\n",
      "\n",
      "============================================================\n",
      "All files processed successfully!\n",
      "Output files saved in: comtrade_monthly_hs4_outputs/merged\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Directory containing the CSV files\n",
    "input_dir = 'comtrade_monthly_hs4_outputs'\n",
    "output_dir = 'comtrade_monthly_hs4_outputs/merged'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def read_csv_with_encoding(file_path):\n",
    "    \"\"\"Read CSV with correct encoding and handle missing column names\"\"\"\n",
    "    encodings = ['latin-1', 'iso-8859-1', 'windows-1252']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            # First read to get the header\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                header_line = f.readline().strip()\n",
    "                data_line = f.readline().strip()\n",
    "            \n",
    "            # Count columns in header vs data\n",
    "            header_cols = header_line.count(',') + 1\n",
    "            data_cols = data_line.count(',') + 1\n",
    "            \n",
    "            if data_cols > header_cols:\n",
    "                # Add placeholder names for missing columns\n",
    "                missing_cols = data_cols - header_cols\n",
    "                print(f\"    Adding {missing_cols} placeholder column names\")\n",
    "                \n",
    "                # Read the original header names\n",
    "                df_temp = pd.read_csv(file_path, encoding=encoding, nrows=0)\n",
    "                original_columns = df_temp.columns.tolist()\n",
    "                \n",
    "                # Add placeholder names\n",
    "                new_columns = original_columns + [f'unnamed_col_{i}' for i in range(missing_cols)]\n",
    "                \n",
    "                # Read with explicit column names\n",
    "                df = pd.read_csv(file_path, encoding=encoding, names=new_columns, skiprows=1)\n",
    "            else:\n",
    "                # Read normally\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except (UnicodeDecodeError, Exception) as e:\n",
    "            continue\n",
    "    \n",
    "    raise Exception(f\"Could not read file with any encoding: {file_path}\")\n",
    "\n",
    "# Define the years and trade types\n",
    "years = [2021, 2022, 2025]\n",
    "trade_types = {'M': 'import', 'X': 'export'}\n",
    "\n",
    "# Process each year and trade type\n",
    "for year in years:\n",
    "    for trade_code, trade_name in trade_types.items():\n",
    "        print(f\"\\nProcessing {year} {trade_name}...\")\n",
    "        \n",
    "        # Find all matching files for this year and trade type\n",
    "        pattern = os.path.join(input_dir, f\"USA_{trade_code}_{year}*_HS4.csv\")\n",
    "        files = sorted(glob(pattern))\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"  No files found for {year} {trade_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Found {len(files)} files\")\n",
    "        \n",
    "        # Read and concatenate all files\n",
    "        dfs = []\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = read_csv_with_encoding(file)\n",
    "                \n",
    "                # Check if 'qty' column exists\n",
    "                if 'qty' not in df.columns:\n",
    "                    print(f\"    ⚠️  'qty' column not found. Available columns: {df.columns.tolist()}\")\n",
    "                    continue\n",
    "                \n",
    "                # Filter rows where qty >= 0\n",
    "                df_filtered = df[df['qty'] >= 0]\n",
    "                dfs.append(df_filtered)\n",
    "                print(f\"    ✓ {os.path.basename(file)}: {len(df)} rows -> {len(df_filtered)} rows after filtering (qty >= 0)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ✗ Error reading {os.path.basename(file)}: {e}\")\n",
    "        \n",
    "        # Concatenate all dataframes\n",
    "        if dfs:\n",
    "            merged_df = pd.concat(dfs, ignore_index=True)\n",
    "            \n",
    "            # Verify columns are correct\n",
    "            print(f\"\\n  Merged dataframe info:\")\n",
    "            print(f\"    Total rows: {len(merged_df):,}\")\n",
    "            print(f\"    First 5 columns: {merged_df.columns[:5].tolist()}\")\n",
    "            print(f\"    Sample data:\")\n",
    "            print(merged_df[['typeCode', 'freqCode', 'refPeriodId', 'qty']].head())\n",
    "            \n",
    "            # Save merged file\n",
    "            output_file = os.path.join(output_dir, f\"USA_{year}_{trade_name}.csv\")\n",
    "            merged_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "            print(f\"\\n  ✓✓ SAVED: {output_file}\")\n",
    "        else:\n",
    "            print(f\"  No data to merge for {year} {trade_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All files processed successfully!\")\n",
    "print(f\"Output files saved in: {output_dir}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d9e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e8c735",
   "metadata": {},
   "source": [
    "## CHINA DATA SPLITTING AND REPAIRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62ba0625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Reading and fixing China data...\n",
      "============================================================\n",
      "\n",
      "Original data:\n",
      "  Total rows: 3,400,928\n",
      "  Columns: 47\n",
      "  First 5 column names: ['typeCode', 'freqCode', 'refPeriodId', 'refYear', 'refMonth']\n",
      "\n",
      "First few rows (before fix):\n",
      "  typeCode  freqCode  refPeriodId  refYear  refMonth\n",
      "0        M  20220201         2022        2    202202\n",
      "1        M  20220201         2022        2    202202\n",
      "2        M  20220201         2022        2    202202\n",
      "3        M  20220201         2022        2    202202\n",
      "4        M  20220201         2022        2    202202\n",
      "\n",
      "After fixing column alignment:\n",
      "  First 5 column names: ['freqCode', 'refPeriodId', 'refYear', 'refMonth', 'period']\n",
      "\n",
      "First few rows (after fix):\n",
      "  freqCode  refPeriodId  refYear  refMonth  period\n",
      "0        M     20220201     2022         2  202202\n",
      "1        M     20220201     2022         2  202202\n",
      "2        M     20220201     2022         2  202202\n",
      "3        M     20220201     2022         2  202202\n",
      "4        M     20220201     2022         2  202202\n",
      "\n",
      "Unique years: [np.int64(2021), np.int64(2022)]\n",
      "Unique flows: ['Import' 'Export']\n",
      "\n",
      "Filtering by qty > 200...\n",
      "  Rows before filtering: 3,400,928\n",
      "  Rows after filtering: 2,362,079\n",
      "\n",
      "============================================================\n",
      "Splitting data by year and trade flow...\n",
      "============================================================\n",
      "✓ Saved: china_2021_import.csv (262,887 rows)\n",
      "✓ Saved: china_2021_export.csv (962,918 rows)\n",
      "✓ Saved: china_2022_import.csv (232,096 rows)\n",
      "✓ Saved: china_2022_export.csv (904,178 rows)\n",
      "\n",
      "============================================================\n",
      "All files saved successfully!\n",
      "Output directory: C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\split\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File path\n",
    "input_file = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\combined_df.csv'\n",
    "output_dir = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\split'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def read_csv_with_encoding(file_path):\n",
    "    \"\"\"Try different encodings\"\"\"\n",
    "    encodings = ['latin-1', 'iso-8859-1', 'windows-1252', 'utf-8']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            return df\n",
    "        except:\n",
    "            continue\n",
    "    raise Exception(\"Could not read file with any encoding\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Reading and fixing China data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Read the CSV\n",
    "df = read_csv_with_encoding(input_file)\n",
    "\n",
    "print(f\"\\nOriginal data:\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"  First 5 column names: {df.columns[:5].tolist()}\")\n",
    "print(f\"\\nFirst few rows (before fix):\")\n",
    "print(df.head()[df.columns[:5]])\n",
    "\n",
    "# Fix the column shift issue\n",
    "# Get the column names\n",
    "old_columns = df.columns.tolist()\n",
    "\n",
    "# Shift column names to the right by 1\n",
    "# Drop the first column name (typeCode) and add a placeholder at the end\n",
    "new_columns = old_columns[1:] + ['unnamed_extra_col']\n",
    "\n",
    "# Apply new column names\n",
    "df.columns = new_columns\n",
    "\n",
    "print(f\"\\nAfter fixing column alignment:\")\n",
    "print(f\"  First 5 column names: {df.columns[:5].tolist()}\")\n",
    "print(f\"\\nFirst few rows (after fix):\")\n",
    "print(df.head()[df.columns[:5]])\n",
    "\n",
    "# Check for required columns\n",
    "if 'refYear' not in df.columns or 'flowDesc' not in df.columns:\n",
    "    print(f\"\\n⚠️  Warning: Required columns not found!\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "else:\n",
    "    # Check unique values\n",
    "    print(f\"\\nUnique years: {sorted(df['refYear'].unique())}\")\n",
    "    print(f\"Unique flows: {df['flowDesc'].unique()}\")\n",
    "    \n",
    "    # Check if qty column exists\n",
    "    if 'qty' in df.columns:\n",
    "        print(f\"\\nFiltering by qty > 200...\")\n",
    "        df_filtered = df[df['qty'] > 200].copy()\n",
    "        print(f\"  Rows before filtering: {len(df):,}\")\n",
    "        print(f\"  Rows after filtering: {len(df_filtered):,}\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  'qty' column not found. Available columns: {df.columns.tolist()}\")\n",
    "        df_filtered = df.copy()\n",
    "    \n",
    "    # Split by year and flow\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"Splitting data by year and trade flow...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    years = sorted(df_filtered['refYear'].unique())\n",
    "    flows = df_filtered['flowDesc'].unique()\n",
    "    \n",
    "    for year in years:\n",
    "        for flow in flows:\n",
    "            # Filter data\n",
    "            mask = (df_filtered['refYear'] == year) & (df_filtered['flowDesc'] == flow)\n",
    "            df_subset = df_filtered[mask]\n",
    "            \n",
    "            if len(df_subset) > 0:\n",
    "                # Create filename (china_2021_import.csv)\n",
    "                flow_name = flow.lower()\n",
    "                filename = f\"china_{year}_{flow_name}.csv\"\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                \n",
    "                # Save file\n",
    "                df_subset.to_csv(output_path, index=False, encoding='utf-8')\n",
    "                print(f\"✓ Saved: {filename} ({len(df_subset):,} rows)\")\n",
    "            else:\n",
    "                print(f\"  No data for {year} {flow}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"All files saved successfully!\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c7d5ba",
   "metadata": {},
   "source": [
    "## RENAMING AND NORMALIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95e64417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing USA files...\n",
      "============================================================\n",
      "\n",
      "USA_2021_export.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 684,538 rows → 591,283 rows\n",
      "  ✓ Saved: USA_2021_export_final.csv\n",
      "    Final rows: 591,283\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 1212\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202101        CUW            9999         268\n",
      "1    202101        ABW            9999         337\n",
      "2    202101        JPN            9999         933\n",
      "3    202101        JAM            9999         521\n",
      "4    202101        GHA            9999         220\n",
      "\n",
      "USA_2021_import.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 434,457 rows → 362,395 rows\n",
      "  ✓ Saved: USA_2021_import_final.csv\n",
      "    Final rows: 362,395\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 1214\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202101        W00             101        1206\n",
      "1    202101        ARG             101         270\n",
      "2    202101        AUS             101         499\n",
      "3    202101        BEL             101         619\n",
      "4    202101        BRA             101         630\n",
      "\n",
      "USA_2022_export.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 691,437 rows → 595,460 rows\n",
      "  ✓ Saved: USA_2022_export_final.csv\n",
      "    Final rows: 595,460\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 1219\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202201        W00             101        1213\n",
      "1    202201        ARG             101         562\n",
      "2    202201        AUS             101         847\n",
      "3    202201        BEL             101         697\n",
      "4    202201        BRA             101         754\n",
      "\n",
      "USA_2022_import.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 460,467 rows → 386,147 rows\n",
      "  ✓ Saved: USA_2022_import_final.csv\n",
      "    Final rows: 386,147\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 1220\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202201        W00             101        1215\n",
      "1    202201        ARG             101         279\n",
      "2    202201        BEL             101         641\n",
      "3    202201        BRA             101         642\n",
      "4    202201        CAN             101        1057\n",
      "\n",
      "USA_2025_export.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 397,384 rows → 343,394 rows\n",
      "  ✓ Saved: USA_2025_export_final.csv\n",
      "    Final rows: 343,394\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 203 to 1216\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202501        NIC            2825         452\n",
      "1    202501        NIC            2933         452\n",
      "2    202501        NIC            3005         452\n",
      "3    202501        NIC            3703         452\n",
      "4    202501        NIC            4203         452\n",
      "\n",
      "USA_2025_import.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 256,889 rows → 219,895 rows\n",
      "  ✓ Saved: USA_2025_import_final.csv\n",
      "    Final rows: 219,895\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 1217\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202501        W00             101        1213\n",
      "1    202501        ARG             101         261\n",
      "2    202501        AUT             101         544\n",
      "3    202501        BEL             101         613\n",
      "4    202501        BRA             101         671\n",
      "\n",
      "============================================================\n",
      "Processing China files...\n",
      "============================================================\n",
      "\n",
      "china_2021_export.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 962,918 rows → 880,648 rows\n",
      "  ✓ Saved: china_2021_export_final.csv\n",
      "    Final rows: 880,648\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 862\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202110        FRA            5702         660\n",
      "1    202110        KGZ            5705         321\n",
      "2    202110        ISR            5702         526\n",
      "3    202110        THA            7004         795\n",
      "4    202110        ECU            3701         489\n",
      "\n",
      "china_2021_import.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 262,887 rows → 191,057 rows\n",
      "  ✓ Saved: china_2021_import_final.csv\n",
      "    Final rows: 191,057\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 206 to 753\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202109        CHN            7003         553\n",
      "1    202109        KOR            2201         639\n",
      "2    202109        MYS            2201         394\n",
      "3    202109        USA            2201         717\n",
      "4    202109        S19            7005         632\n",
      "\n",
      "china_2022_export.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 904,178 rows → 827,111 rows\n",
      "  ✓ Saved: china_2022_export_final.csv\n",
      "    Final rows: 827,111\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 861\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202209        HKG             102         797\n",
      "1    202209        HKG             103         797\n",
      "2    202209        MAC             103         434\n",
      "3    202209        HKG             105         797\n",
      "4    202209        CAN             106         707\n",
      "\n",
      "china_2022_import.csv\n",
      "    Calculating nb_product (distinct products per month/country)...\n",
      "    Filtered nb_product > 200: 232,096 rows → 167,889 rows\n",
      "  ✓ Saved: china_2022_import_final.csv\n",
      "    Final rows: 167,889\n",
      "    Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
      "    nb_product range: 201 to 741\n",
      "    Sample data:\n",
      "   month_id country_id  product_id_hs4  nb_product\n",
      "0    202202        AUS             102         241\n",
      "1    202202        USA             105         673\n",
      "2    202202        USA             106         673\n",
      "3    202202        AUS             201         241\n",
      "4    202202        USA             201         673\n",
      "\n",
      "============================================================\n",
      "All files processed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define directories\n",
    "usa_dir = 'comtrade_monthly_hs4_outputs/merged'\n",
    "china_dir = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\split'\n",
    "\n",
    "# Column mapping: old_name -> new_name\n",
    "column_mapping = {\n",
    "    'period': 'month_id',\n",
    "    'flowDesc': 'trade_flow_name',\n",
    "    'partnerISO': 'country_id',\n",
    "    'partnerDesc': 'country_name',\n",
    "    'cmdCode': 'product_id_hs4',\n",
    "    'primaryValue': 'trade_value',\n",
    "    'qty': 'quantity',\n",
    "    'cmdDesc': 'product_name_hs4'\n",
    "}\n",
    "\n",
    "# Final column order\n",
    "final_columns = ['month_id', 'trade_flow_name', 'country_id', 'country_name', \n",
    "                 'product_id_hs4', 'trade_value', 'quantity', 'nb_product', 'product_name_hs4']\n",
    "\n",
    "def read_csv_with_encoding(file_path):\n",
    "    \"\"\"Try different encodings\"\"\"\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            return df\n",
    "        except:\n",
    "            continue\n",
    "    raise Exception(f\"Could not read file: {file_path}\")\n",
    "\n",
    "def process_file(input_path, output_path):\n",
    "    \"\"\"Process a single file: select columns, rename, filter, and save\"\"\"\n",
    "    try:\n",
    "        # Read file\n",
    "        df = read_csv_with_encoding(input_path)\n",
    "        \n",
    "        # Check if all required columns exist\n",
    "        missing_cols = [col for col in column_mapping.keys() if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"  ⚠️  Missing columns: {missing_cols}\")\n",
    "            print(f\"      Available columns: {df.columns.tolist()}\")\n",
    "            return False\n",
    "        \n",
    "        # Select only the columns we need\n",
    "        df_selected = df[list(column_mapping.keys())].copy()\n",
    "        \n",
    "        # Rename columns\n",
    "        df_renamed = df_selected.rename(columns=column_mapping)\n",
    "        \n",
    "        # Convert product_id_hs4 to string\n",
    "        df_renamed['product_id_hs4'] = df_renamed['product_id_hs4'].astype(str)\n",
    "        \n",
    "        # Calculate nb_product: count distinct products per month_id and country_id\n",
    "        print(f\"    Calculating nb_product (distinct products per month/country)...\")\n",
    "        df_renamed['nb_product'] = df_renamed.groupby(['month_id', 'country_id'])['product_id_hs4'].transform('nunique')\n",
    "        \n",
    "        # Filter: keep only rows where nb_product > 200\n",
    "        rows_before = len(df_renamed)\n",
    "        df_filtered = df_renamed[df_renamed['nb_product'] > 200].copy()\n",
    "        rows_after = len(df_filtered)\n",
    "        print(f\"    Filtered nb_product > 200: {rows_before:,} rows → {rows_after:,} rows\")\n",
    "        \n",
    "        # Reorder columns\n",
    "        df_final = df_filtered[final_columns]\n",
    "        \n",
    "        # Save\n",
    "        df_final.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing USA files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process USA files\n",
    "usa_files = glob(os.path.join(usa_dir, \"USA_*.csv\"))\n",
    "for file_path in usa_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Skip if already a _final file\n",
    "    if '_final' in filename:\n",
    "        continue\n",
    "    if '_Additional' in filename:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # Create output filename\n",
    "    name_without_ext = filename.replace('.csv', '')\n",
    "    output_filename = f\"{name_without_ext}_final.csv\"\n",
    "    output_path = os.path.join(usa_dir, output_filename)\n",
    "    \n",
    "    print(f\"\\n{filename}\")\n",
    "    success = process_file(file_path, output_path)\n",
    "    \n",
    "    if success:\n",
    "        # Check file size\n",
    "        df_check = pd.read_csv(output_path)\n",
    "        print(f\"  ✓ Saved: {output_filename}\")\n",
    "        print(f\"    Final rows: {len(df_check):,}\")\n",
    "        print(f\"    Columns: {df_check.columns.tolist()}\")\n",
    "        print(f\"    nb_product range: {df_check['nb_product'].min()} to {df_check['nb_product'].max()}\")\n",
    "        print(f\"    Sample data:\")\n",
    "        print(df_check[['month_id', 'country_id', 'product_id_hs4', 'nb_product']].head(5))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Processing China files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process China files\n",
    "china_files = glob(os.path.join(china_dir, \"china_*.csv\"))\n",
    "for file_path in china_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Skip if already a _final file\n",
    "    if '_final' in filename:\n",
    "        continue\n",
    "    if '_Additional' in filename:\n",
    "        continue\n",
    "\n",
    "    # Create output filename\n",
    "    name_without_ext = filename.replace('.csv', '')\n",
    "    output_filename = f\"{name_without_ext}_final.csv\"\n",
    "    output_path = os.path.join(china_dir, output_filename)\n",
    "    \n",
    "    print(f\"\\n{filename}\")\n",
    "    success = process_file(file_path, output_path)\n",
    "    \n",
    "    if success:\n",
    "        # Check file size\n",
    "        df_check = pd.read_csv(output_path)\n",
    "        print(f\"  ✓ Saved: {output_filename}\")\n",
    "        print(f\"    Final rows: {len(df_check):,}\")\n",
    "        print(f\"    Columns: {df_check.columns.tolist()}\")\n",
    "        print(f\"    nb_product range: {df_check['nb_product'].min()} to {df_check['nb_product'].max()}\")\n",
    "        print(f\"    Sample data:\")\n",
    "        print(df_check[['month_id', 'country_id', 'product_id_hs4', 'nb_product']].head(5))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All files processed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dea568",
   "metadata": {},
   "source": [
    "## ADDITIONAL DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "775bc4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: Loading and preparing indicators data...\n",
      "============================================================\n",
      "\n",
      "✓ Loaded indicators data: 157,410 rows\n",
      "\n",
      "Checking available indicators...\n",
      "Unique indicators in data:\n",
      "  - Final consumption expenditure: 12801 rows\n",
      "  - Gross domestic product (GDP): 20517 rows\n",
      "  - Gross fixed capital formation: 15483 rows\n",
      "  - Final consumption expenditure, General government: 15687 rows\n",
      "  - Individual consumption expenditure, General government: 1386 rows\n",
      "  - Gross capital formation: 14172 rows\n",
      "  - Final consumption expenditure, Private sector: 15477 rows\n",
      "  - Final consumption expenditure, Households: 2103 rows\n",
      "  - Changes in inventories, Private sector: 5154 rows\n",
      "  - Changes in inventories: 14745 rows\n",
      "  - Final consumption expenditure, Non profit institutions serving households: 1626 rows\n",
      "  - Collective consumption expenditure, General government: 1350 rows\n",
      "\n",
      "Unique PRICE_TYPE: ['Constant prices' 'Current prices' 'Price deflator']\n",
      "Unique S_ADJUSTMENT: ['Seasonally adjusted (SA)' 'Not seasonally adjusted (NSA)']\n",
      "\n",
      "✓ Filtered indicators: 23,469 rows\n",
      "Indicators found:\n",
      "  - Final consumption expenditure: 3048 rows\n",
      "  - Gross domestic product (GDP): 3573 rows\n",
      "  - Gross fixed capital formation: 3273 rows\n",
      "  - Final consumption expenditure, General government: 3324 rows\n",
      "  - Gross capital formation: 2856 rows\n",
      "  - Final consumption expenditure, Private sector: 3144 rows\n",
      "  - Final consumption expenditure, Households: 201 rows\n",
      "  - Changes in inventories: 2958 rows\n",
      "  - Changes in inventories, Private sector: 771 rows\n",
      "  - Individual consumption expenditure, General government: 93 rows\n",
      "  - Final consumption expenditure, Non profit institutions serving households: 144 rows\n",
      "  - Collective consumption expenditure, General government: 84 rows\n",
      "\n",
      "  Pivoting indicators to wide format...\n",
      "  Pivoted data shape: (2916, 14)\n",
      "  Columns: ['country_id', 'month_id', 'changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'Collective consumption expenditure, General government', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa', 'Gross fixed capital formation', 'Individual consumption expenditure, General government']\n",
      "\n",
      "============================================================\n",
      "STEP 2: Loading and preparing REER data...\n",
      "============================================================\n",
      "\n",
      "✓ Loaded REER data: 93 rows\n",
      "  Columns: ['DATASET', 'SERIES_CODE', 'OBS_MEASURE', 'COUNTRY.ID', 'COUNTRY', 'INDICATOR.ID', 'INDICATOR', 'FREQUENCY.ID', 'FREQUENCY', 'SCALE.ID', 'SCALE', '2021-M01', '2021-M02', '2021-M03', '2021-M04']...\n",
      "\n",
      "Unique INDICATOR values:\n",
      "  - Real effective exchange rate (REER), Index (2010=100) Adjusted by relative consumer prices\n",
      "\n",
      "✓ Filtered for REER: 93 rows\n",
      "  Found 55 date columns from 2021-M01 to 2025-M07\n",
      "\n",
      "  Transforming REER data from wide to long format...\n",
      "  Final REER data shape: (5115, 3)\n",
      "  Sample:\n",
      "  country_id  month_id        REER\n",
      "0        SGP    202101  102.953078\n",
      "1        CHN    202101  125.883685\n",
      "2        CYP    202101   87.749693\n",
      "3        ITA    202101   95.820473\n",
      "4        ZMB    202101   60.087071\n",
      "5        USA    202101  112.086887\n",
      "6        ESP    202101   97.832052\n",
      "7        TUN    202101   85.148376\n",
      "8        MYS    202101   84.537945\n",
      "9        VCT    202101   98.798993\n",
      "\n",
      "============================================================\n",
      "STEP 3: Processing USA files...\n",
      "============================================================\n",
      "\n",
      "USA_2021_export_final.csv\n",
      "  Original rows: 591,283\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 321,432\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 369,624\n",
      "  ✓ Saved: USA_2021_export_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "USA_2021_import_final.csv\n",
      "  Original rows: 362,395\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 254,962\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 261,677\n",
      "  ✓ Saved: USA_2021_import_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "USA_2022_export_final.csv\n",
      "  Original rows: 595,460\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 321,931\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 368,772\n",
      "  ✓ Saved: USA_2022_export_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "USA_2022_import_final.csv\n",
      "  Original rows: 386,147\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 261,604\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 272,490\n",
      "  ✓ Saved: USA_2022_import_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "USA_2025_export_final.csv\n",
      "  Original rows: 343,394\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 134,587\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 213,023\n",
      "  ✓ Saved: USA_2025_export_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "USA_2025_import_final.csv\n",
      "  Original rows: 219,895\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 115,754\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 153,913\n",
      "  ✓ Saved: USA_2025_import_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "============================================================\n",
      "STEP 4: Processing China files...\n",
      "============================================================\n",
      "\n",
      "china_2021_export_final.csv\n",
      "  Original rows: 880,648\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 388,202\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 469,964\n",
      "  ✓ Saved: china_2021_export_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "china_2021_import_final.csv\n",
      "  Original rows: 191,057\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 139,336\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 136,881\n",
      "  ✓ Saved: china_2021_import_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "china_2022_export_final.csv\n",
      "  Original rows: 827,111\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 354,885\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 435,645\n",
      "  ✓ Saved: china_2022_export_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "china_2022_import_final.csv\n",
      "  Original rows: 167,889\n",
      "  ✓ Added 9 indicator columns\n",
      "    Rows with at least one indicator: 122,829\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 120,028\n",
      "  ✓ Saved: china_2022_import_Additional.csv\n",
      "    Total columns: 22\n",
      "    Indicator columns: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "\n",
      "============================================================\n",
      "All files processed successfully!\n",
      "============================================================\n",
      "\n",
      "New columns added:\n",
      "  - gdp_constant_sa (if available in data)\n",
      "  - final_consumption_constant_sa\n",
      "  - gross_capital_formation_constant_sa\n",
      "  - changes_inventories_constant_sa\n",
      "  - REER (Real Effective Exchange Rate)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define directories and file paths\n",
    "usa_dir = 'comtrade_monthly_hs4_outputs/merged'\n",
    "china_dir = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\split'\n",
    "indicators_file = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\df_long.csv'\n",
    "reer_file = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\outputs\\EER_COUNTRIES.csv'\n",
    "\n",
    "def read_csv_with_encoding(file_path):\n",
    "    \"\"\"Try different encodings\"\"\"\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            return df\n",
    "        except:\n",
    "            continue\n",
    "    raise Exception(f\"Could not read file: {file_path}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: Loading and preparing indicators data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load indicators data\n",
    "df_indicators = read_csv_with_encoding(indicators_file)\n",
    "print(f\"\\n✓ Loaded indicators data: {len(df_indicators):,} rows\")\n",
    "\n",
    "# Check what indicators are available\n",
    "print(f\"\\nChecking available indicators...\")\n",
    "print(f\"Unique indicators in data:\")\n",
    "for ind in df_indicators['INDICATOR'].unique():\n",
    "    if 'GDP' in ind.upper() or 'GROSS' in ind.upper() or 'CONSUMPTION' in ind.upper() or 'CAPITAL' in ind.upper() or 'INVENTOR' in ind.upper():\n",
    "        count = len(df_indicators[df_indicators['INDICATOR'] == ind])\n",
    "        print(f\"  - {ind}: {count} rows\")\n",
    "\n",
    "# Let's check filters\n",
    "print(f\"\\nUnique PRICE_TYPE: {df_indicators['PRICE_TYPE'].unique()}\")\n",
    "print(f\"Unique S_ADJUSTMENT: {df_indicators['S_ADJUSTMENT'].unique()}\")\n",
    "\n",
    "# Filter indicators - let's be more flexible with GDP name\n",
    "indicator_keywords = ['GDP', 'consumption expenditure', 'capital formation', 'inventories']\n",
    "\n",
    "df_indicators_filtered = df_indicators[\n",
    "    (df_indicators['PRICE_TYPE'] == 'Constant prices') &\n",
    "    (df_indicators['S_ADJUSTMENT'] == 'Seasonally adjusted (SA)') &\n",
    "    (df_indicators['INDICATOR'].apply(lambda x: any(keyword.lower() in x.lower() for keyword in indicator_keywords)))\n",
    "].copy()\n",
    "\n",
    "print(f\"\\n✓ Filtered indicators: {len(df_indicators_filtered):,} rows\")\n",
    "print(f\"Indicators found:\")\n",
    "for ind in df_indicators_filtered['INDICATOR'].unique():\n",
    "    count = len(df_indicators_filtered[df_indicators_filtered['INDICATOR'] == ind])\n",
    "    print(f\"  - {ind}: {count} rows\")\n",
    "\n",
    "# Pivot indicators to create one column per indicator\n",
    "print(f\"\\n  Pivoting indicators to wide format...\")\n",
    "df_indicators_wide = df_indicators_filtered.pivot_table(\n",
    "    index=['ISO3', 'PERIOD'],\n",
    "    columns='INDICATOR',\n",
    "    values='VALUE',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns\n",
    "column_rename = {\n",
    "    'ISO3': 'country_id',\n",
    "    'PERIOD': 'month_id'\n",
    "}\n",
    "\n",
    "# Add renaming for each indicator found\n",
    "for col in df_indicators_wide.columns:\n",
    "    if 'GDP' in col or 'Gross domestic product' in col:\n",
    "        column_rename[col] = 'gdp_constant_sa'\n",
    "    elif 'Final consumption expenditure' in col:\n",
    "        column_rename[col] = 'final_consumption_constant_sa'\n",
    "    elif 'Gross capital formation' in col:\n",
    "        column_rename[col] = 'gross_capital_formation_constant_sa'\n",
    "    elif 'Changes in inventories' in col:\n",
    "        column_rename[col] = 'changes_inventories_constant_sa'\n",
    "\n",
    "df_indicators_wide = df_indicators_wide.rename(columns=column_rename)\n",
    "\n",
    "print(f\"  Pivoted data shape: {df_indicators_wide.shape}\")\n",
    "print(f\"  Columns: {df_indicators_wide.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: Loading and preparing REER data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load REER data\n",
    "df_reer = read_csv_with_encoding(reer_file)\n",
    "print(f\"\\n✓ Loaded REER data: {len(df_reer)} rows\")\n",
    "print(f\"  Columns: {df_reer.columns.tolist()[:15]}...\")  # First 15 columns\n",
    "\n",
    "# Check indicators available\n",
    "print(f\"\\nUnique INDICATOR values:\")\n",
    "for ind in df_reer['INDICATOR'].unique():\n",
    "    print(f\"  - {ind}\")\n",
    "\n",
    "# Filter for REER only\n",
    "df_reer_filtered = df_reer[df_reer['INDICATOR'].str.contains('REER', case=False, na=False)].copy()\n",
    "print(f\"\\n✓ Filtered for REER: {len(df_reer_filtered)} rows\")\n",
    "\n",
    "# Get the date columns (format: 2021-M01, 2021-M02, etc.)\n",
    "date_columns = [col for col in df_reer_filtered.columns if '-M' in col]\n",
    "print(f\"  Found {len(date_columns)} date columns from {date_columns[0]} to {date_columns[-1]}\")\n",
    "\n",
    "# Transform from wide to long format\n",
    "print(f\"\\n  Transforming REER data from wide to long format...\")\n",
    "\n",
    "# Melt the dataframe\n",
    "df_reer_long = df_reer_filtered.melt(\n",
    "    id_vars=['COUNTRY.ID'],\n",
    "    value_vars=date_columns,\n",
    "    var_name='period_str',\n",
    "    value_name='REER'\n",
    ")\n",
    "\n",
    "# Convert period format from \"2021-M01\" to \"202101\"\n",
    "df_reer_long['month_id'] = df_reer_long['period_str'].str.replace('-M', '').astype(int)\n",
    "\n",
    "# Rename COUNTRY.ID to country_id\n",
    "df_reer_long = df_reer_long.rename(columns={'COUNTRY.ID': 'country_id'})\n",
    "\n",
    "# Keep only country_id, month_id, and REER\n",
    "df_reer_final = df_reer_long[['country_id', 'month_id', 'REER']].copy()\n",
    "\n",
    "# Remove rows with missing REER values\n",
    "df_reer_final = df_reer_final.dropna(subset=['REER'])\n",
    "\n",
    "print(f\"  Final REER data shape: {df_reer_final.shape}\")\n",
    "print(f\"  Sample:\")\n",
    "print(df_reer_final.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: Processing USA files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process USA files\n",
    "usa_files = glob(os.path.join(usa_dir, \"USA_*_final.csv\"))\n",
    "for file_path in usa_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    print(f\"\\n{filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Read file\n",
    "        df = read_csv_with_encoding(file_path)\n",
    "        print(f\"  Original rows: {len(df):,}\")\n",
    "        \n",
    "        # Merge with indicators\n",
    "        df_merged = df.merge(\n",
    "            df_indicators_wide,\n",
    "            on=['country_id', 'month_id'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        indicator_cols = [col for col in df_merged.columns if '_constant_sa' in col]\n",
    "        rows_with_indicators = df_merged[indicator_cols].notna().any(axis=1).sum()\n",
    "        print(f\"  ✓ Added {len(indicator_cols)} indicator columns\")\n",
    "        print(f\"    Rows with at least one indicator: {rows_with_indicators:,}\")\n",
    "        \n",
    "        # Merge with REER\n",
    "        df_merged = df_merged.merge(\n",
    "            df_reer_final,\n",
    "            on=['country_id', 'month_id'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        rows_with_reer = df_merged['REER'].notna().sum()\n",
    "        print(f\"  ✓ Added REER column\")\n",
    "        print(f\"    Rows with REER data: {rows_with_reer:,}\")\n",
    "        \n",
    "        # Save\n",
    "        output_filename = filename.replace('_final.csv', '_Additional.csv')\n",
    "        output_path = os.path.join(usa_dir, output_filename)\n",
    "        df_merged.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"  ✓ Saved: {output_filename}\")\n",
    "        print(f\"    Total columns: {len(df_merged.columns)}\")\n",
    "        print(f\"    Indicator columns: {indicator_cols}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 4: Processing China files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process China files\n",
    "china_files = glob(os.path.join(china_dir, \"china_*_final.csv\"))\n",
    "for file_path in china_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    print(f\"\\n{filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Read file\n",
    "        df = read_csv_with_encoding(file_path)\n",
    "        print(f\"  Original rows: {len(df):,}\")\n",
    "        \n",
    "        # Merge with indicators\n",
    "        df_merged = df.merge(\n",
    "            df_indicators_wide,\n",
    "            on=['country_id', 'month_id'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        indicator_cols = [col for col in df_merged.columns if '_constant_sa' in col]\n",
    "        rows_with_indicators = df_merged[indicator_cols].notna().any(axis=1).sum()\n",
    "        print(f\"  ✓ Added {len(indicator_cols)} indicator columns\")\n",
    "        print(f\"    Rows with at least one indicator: {rows_with_indicators:,}\")\n",
    "        \n",
    "        # Merge with REER\n",
    "        df_merged = df_merged.merge(\n",
    "            df_reer_final,\n",
    "            on=['country_id', 'month_id'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        rows_with_reer = df_merged['REER'].notna().sum()\n",
    "        print(f\"  ✓ Added REER column\")\n",
    "        print(f\"    Rows with REER data: {rows_with_reer:,}\")\n",
    "        \n",
    "        # Save\n",
    "        output_filename = filename.replace('_final.csv', '_Additional.csv')\n",
    "        output_path = os.path.join(china_dir, output_filename)\n",
    "        df_merged.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"  ✓ Saved: {output_filename}\")\n",
    "        print(f\"    Total columns: {len(df_merged.columns)}\")\n",
    "        print(f\"    Indicator columns: {indicator_cols}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All files processed successfully!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNew columns added:\")\n",
    "print(\"  - gdp_constant_sa (if available in data)\")\n",
    "print(\"  - final_consumption_constant_sa\")\n",
    "print(\"  - gross_capital_formation_constant_sa\")\n",
    "print(\"  - changes_inventories_constant_sa\")\n",
    "print(\"  - REER (Real Effective Exchange Rate)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59698f06",
   "metadata": {},
   "source": [
    "### ADDITIONAL DATA 2023 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bfed376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARATION: Loading reference data...\n",
      "============================================================\n",
      "\n",
      "✓ Loaded indicators data: 157,410 rows\n",
      "✓ Filtered indicators: 23,469 rows\n",
      "Indicators found: ['Final consumption expenditure', 'Gross domestic product (GDP)', 'Gross fixed capital formation', 'Final consumption expenditure, General government', 'Gross capital formation', 'Final consumption expenditure, Private sector', 'Final consumption expenditure, Households', 'Changes in inventories', 'Changes in inventories, Private sector', 'Individual consumption expenditure, General government', 'Final consumption expenditure, Non profit institutions serving households', 'Collective consumption expenditure, General government']\n",
      "✓ Pivoted indicators: (2916, 14)\n",
      "\n",
      "✓ Loaded REER data: 93 rows\n",
      "✓ Prepared REER data: (5115, 3)\n",
      "\n",
      "============================================================\n",
      "STEP 1: Splitting files by trade flow...\n",
      "============================================================\n",
      "\n",
      "USA_2023_finale.csv\n",
      "  Original rows: 1,574,554\n",
      "  Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'nb_product', 'product_name_hs4']\n",
      "  Trade flows found: ['Imports' 'Exports']\n",
      "    ✓ USA_2023_imports_final.csv: 582,945 rows\n",
      "    ✓ USA_2023_exports_final.csv: 991,609 rows\n",
      "\n",
      "USA_2024_finale.csv\n",
      "  Original rows: 1,564,778\n",
      "  Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'nb_product', 'product_name_hs4']\n",
      "  Trade flows found: ['Imports' 'Exports']\n",
      "    ✓ USA_2024_imports_final.csv: 582,635 rows\n",
      "    ✓ USA_2024_exports_final.csv: 982,143 rows\n",
      "\n",
      "china_2023_finale.csv\n",
      "  Original rows: 1,567,084\n",
      "  Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'nb_product', 'product_name_hs4']\n",
      "  Trade flows found: ['Exports' 'Imports']\n",
      "    ✓ china_2023_exports_final.csv: 1,219,343 rows\n",
      "    ✓ china_2023_imports_final.csv: 347,741 rows\n",
      "\n",
      "china_2024_finale.csv\n",
      "  Original rows: 1,571,701\n",
      "  Columns: ['month_id', 'trade_flow_name', 'country_id', 'country_name', 'product_id_hs4', 'trade_value', 'nb_product', 'product_name_hs4']\n",
      "  Trade flows found: ['Imports' 'Exports']\n",
      "    ✓ china_2024_imports_final.csv: 348,841 rows\n",
      "    ✓ china_2024_exports_final.csv: 1,222,860 rows\n",
      "\n",
      "============================================================\n",
      "STEP 2: Adding indicators and REER to create _Additional files...\n",
      "============================================================\n",
      "\n",
      "USA_2023_imports_final.csv\n",
      "  Original rows: 582,945\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 356,191\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 394,526\n",
      "  ✓ Saved: USA_2023_imports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "USA_2023_exports_final.csv\n",
      "  Original rows: 991,609\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 456,203\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 580,374\n",
      "  ✓ Saved: USA_2023_exports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "USA_2024_imports_final.csv\n",
      "  Original rows: 582,635\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 350,320\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 394,368\n",
      "  ✓ Saved: USA_2024_imports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "USA_2024_exports_final.csv\n",
      "  Original rows: 982,143\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 433,995\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 574,234\n",
      "  ✓ Saved: USA_2024_exports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "china_2023_exports_final.csv\n",
      "  Original rows: 1,219,343\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 477,940\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 620,672\n",
      "  ✓ Saved: china_2023_exports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "china_2023_imports_final.csv\n",
      "  Original rows: 347,741\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 227,858\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 242,107\n",
      "  ✓ Saved: china_2023_imports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "china_2024_imports_final.csv\n",
      "  Original rows: 348,841\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 226,050\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 242,607\n",
      "  ✓ Saved: china_2024_imports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "china_2024_exports_final.csv\n",
      "  Original rows: 1,222,860\n",
      "  ✓ Added 9 indicator columns\n",
      "    Indicators: ['changes_inventories_constant_sa', 'changes_inventories_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'final_consumption_constant_sa', 'gross_capital_formation_constant_sa', 'gdp_constant_sa']\n",
      "    Rows with at least one indicator: 452,934\n",
      "  ✓ Added REER column\n",
      "    Rows with REER data: 617,087\n",
      "  ✓ Saved: china_2024_exports_Additional.csv\n",
      "    Total columns: 21\n",
      "\n",
      "============================================================\n",
      "All files processed successfully!\n",
      "============================================================\n",
      "\n",
      "Output files created:\n",
      "  Step 1 - Split by trade flow (8 files):\n",
      "    - USA_2023_imports_final.csv\n",
      "    - USA_2023_exports_final.csv\n",
      "    - USA_2024_imports_final.csv\n",
      "    - USA_2024_exports_final.csv\n",
      "    - china_2023_exports_final.csv\n",
      "    - china_2023_imports_final.csv\n",
      "    - china_2024_imports_final.csv\n",
      "    - china_2024_exports_final.csv\n",
      "\n",
      "  Step 2 - Added indicators and REER (8 files):\n",
      "    - USA_2023_imports_Additional.csv\n",
      "    - USA_2023_exports_Additional.csv\n",
      "    - USA_2024_imports_Additional.csv\n",
      "    - USA_2024_exports_Additional.csv\n",
      "    - china_2023_exports_Additional.csv\n",
      "    - china_2023_imports_Additional.csv\n",
      "    - china_2024_imports_Additional.csv\n",
      "    - china_2024_exports_Additional.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define directories and file paths\n",
    "input_dir = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\processed_input_data'\n",
    "indicators_file = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\Data\\china and gdp data\\china and gdp data\\df_long.csv'\n",
    "reer_file = r'C:\\Users\\wb636273\\OneDrive - WBG\\Documents\\AI4TRADE\\outputs\\EER_COUNTRIES.csv'\n",
    "\n",
    "def read_csv_with_encoding(file_path):\n",
    "    \"\"\"Try different encodings\"\"\"\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            return df\n",
    "        except:\n",
    "            continue\n",
    "    raise Exception(f\"Could not read file: {file_path}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPARATION: Loading reference data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load indicators data\n",
    "df_indicators = read_csv_with_encoding(indicators_file)\n",
    "print(f\"\\n✓ Loaded indicators data: {len(df_indicators):,} rows\")\n",
    "\n",
    "# Filter indicators\n",
    "indicator_keywords = ['GDP', 'consumption expenditure', 'capital formation', 'inventories']\n",
    "\n",
    "df_indicators_filtered = df_indicators[\n",
    "    (df_indicators['PRICE_TYPE'] == 'Constant prices') &\n",
    "    (df_indicators['S_ADJUSTMENT'] == 'Seasonally adjusted (SA)') &\n",
    "    (df_indicators['INDICATOR'].apply(lambda x: any(keyword.lower() in x.lower() for keyword in indicator_keywords)))\n",
    "].copy()\n",
    "\n",
    "print(f\"✓ Filtered indicators: {len(df_indicators_filtered):,} rows\")\n",
    "print(f\"Indicators found: {df_indicators_filtered['INDICATOR'].unique().tolist()}\")\n",
    "\n",
    "# Pivot indicators\n",
    "df_indicators_wide = df_indicators_filtered.pivot_table(\n",
    "    index=['ISO3', 'PERIOD'],\n",
    "    columns='INDICATOR',\n",
    "    values='VALUE',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns\n",
    "column_rename = {\n",
    "    'ISO3': 'country_id',\n",
    "    'PERIOD': 'month_id'\n",
    "}\n",
    "\n",
    "for col in df_indicators_wide.columns:\n",
    "    if 'GDP' in col or 'Gross domestic product' in col:\n",
    "        column_rename[col] = 'gdp_constant_sa'\n",
    "    elif 'Final consumption expenditure' in col:\n",
    "        column_rename[col] = 'final_consumption_constant_sa'\n",
    "    elif 'Gross capital formation' in col:\n",
    "        column_rename[col] = 'gross_capital_formation_constant_sa'\n",
    "    elif 'Changes in inventories' in col:\n",
    "        column_rename[col] = 'changes_inventories_constant_sa'\n",
    "\n",
    "df_indicators_wide = df_indicators_wide.rename(columns=column_rename)\n",
    "print(f\"✓ Pivoted indicators: {df_indicators_wide.shape}\")\n",
    "\n",
    "# Load REER data\n",
    "df_reer = read_csv_with_encoding(reer_file)\n",
    "print(f\"\\n✓ Loaded REER data: {len(df_reer)} rows\")\n",
    "\n",
    "# Filter for REER\n",
    "df_reer_filtered = df_reer[df_reer['INDICATOR'].str.contains('REER', case=False, na=False)].copy()\n",
    "\n",
    "# Get date columns\n",
    "date_columns = [col for col in df_reer_filtered.columns if '-M' in col]\n",
    "\n",
    "# Melt to long format\n",
    "df_reer_long = df_reer_filtered.melt(\n",
    "    id_vars=['COUNTRY.ID'],\n",
    "    value_vars=date_columns,\n",
    "    var_name='period_str',\n",
    "    value_name='REER'\n",
    ")\n",
    "\n",
    "# Convert period format\n",
    "df_reer_long['month_id'] = df_reer_long['period_str'].str.replace('-M', '').astype(int)\n",
    "df_reer_long = df_reer_long.rename(columns={'COUNTRY.ID': 'country_id'})\n",
    "df_reer_final = df_reer_long[['country_id', 'month_id', 'REER']].dropna(subset=['REER'])\n",
    "\n",
    "print(f\"✓ Prepared REER data: {df_reer_final.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 1: Splitting files by trade flow...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Files to process\n",
    "files_to_process = [\n",
    "    'USA_2023_finale.csv',\n",
    "    'USA_2024_finale.csv',\n",
    "    'china_2023_finale.csv',\n",
    "    'china_2024_finale.csv'\n",
    "]\n",
    "\n",
    "split_files = []  # Keep track of split files for next step\n",
    "\n",
    "for filename in files_to_process:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"\\n⚠️  File not found: {filename}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Read file\n",
    "        df = read_csv_with_encoding(file_path)\n",
    "        print(f\"  Original rows: {len(df):,}\")\n",
    "        print(f\"  Columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Check if trade_flow_name exists\n",
    "        if 'trade_flow_name' not in df.columns:\n",
    "            print(f\"  ⚠️  'trade_flow_name' column not found!\")\n",
    "            continue\n",
    "        \n",
    "        # Get unique trade flows\n",
    "        trade_flows = df['trade_flow_name'].unique()\n",
    "        print(f\"  Trade flows found: {trade_flows}\")\n",
    "        \n",
    "        # Extract country and year from filename\n",
    "        # e.g., \"USA_2023_finale.csv\" -> \"USA\", \"2023\"\n",
    "        parts = filename.replace('_finale.csv', '').split('_')\n",
    "        country = parts[0]\n",
    "        year = parts[1]\n",
    "        \n",
    "        # Split by trade flow\n",
    "        for flow in trade_flows:\n",
    "            df_flow = df[df['trade_flow_name'] == flow].copy()\n",
    "            \n",
    "            # Create filename\n",
    "            flow_name = flow.lower()\n",
    "            output_filename = f\"{country}_{year}_{flow_name}_final.csv\"\n",
    "            output_path = os.path.join(input_dir, output_filename)\n",
    "            \n",
    "            # Save\n",
    "            df_flow.to_csv(output_path, index=False, encoding='utf-8')\n",
    "            print(f\"    ✓ {output_filename}: {len(df_flow):,} rows\")\n",
    "            \n",
    "            # Track for next step\n",
    "            split_files.append(output_filename)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: Adding indicators and REER to create _Additional files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for filename in split_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    print(f\"\\n{filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Read file\n",
    "        df = read_csv_with_encoding(file_path)\n",
    "        df[\"country_id\"] = df[\"country_id\"].str.upper()\n",
    "        print(f\"  Original rows: {len(df):,}\")\n",
    "        \n",
    "        # Check required columns\n",
    "        if 'country_id' not in df.columns or 'month_id' not in df.columns:\n",
    "            print(f\"  ⚠️  Required columns (country_id, month_id) not found!\")\n",
    "            print(f\"      Available columns: {df.columns.tolist()}\")\n",
    "            continue\n",
    "        \n",
    "        # Merge with indicators\n",
    "        df_merged = df.merge(\n",
    "            df_indicators_wide,\n",
    "            on=['country_id', 'month_id'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        indicator_cols = [col for col in df_merged.columns if '_constant_sa' in col]\n",
    "        rows_with_indicators = df_merged[indicator_cols].notna().any(axis=1).sum()\n",
    "        print(f\"  ✓ Added {len(indicator_cols)} indicator columns\")\n",
    "        print(f\"    Indicators: {indicator_cols}\")\n",
    "        print(f\"    Rows with at least one indicator: {rows_with_indicators:,}\")\n",
    "        \n",
    "        # Merge with REER\n",
    "        df_merged = df_merged.merge(\n",
    "            df_reer_final,\n",
    "            on=['country_id', 'month_id'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        rows_with_reer = df_merged['REER'].notna().sum()\n",
    "        print(f\"  ✓ Added REER column\")\n",
    "        print(f\"    Rows with REER data: {rows_with_reer:,}\")\n",
    "        \n",
    "        # Save\n",
    "        output_filename = filename.replace('_final.csv', '_Additional.csv')\n",
    "        output_path = os.path.join(input_dir, output_filename)\n",
    "        df_merged.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"  ✓ Saved: {output_filename}\")\n",
    "        print(f\"    Total columns: {len(df_merged.columns)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All files processed successfully!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nOutput files created:\")\n",
    "print(\"  Step 1 - Split by trade flow (8 files):\")\n",
    "for f in split_files:\n",
    "    print(f\"    - {f}\")\n",
    "print(\"\\n  Step 2 - Added indicators and REER (8 files):\")\n",
    "for f in split_files:\n",
    "    print(f\"    - {f.replace('_final.csv', '_Additional.csv')}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capexdx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
